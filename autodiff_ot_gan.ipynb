{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model for the MLP is the same as in the paper. Two input neurons, a hidden layer with 500 units and an output layer with 784 units. We choose the ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "    \"\"\"\n",
    "    A MLP with 1 hidden layer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "    Constructor of the MLP.\n",
    "    Arguments:\n",
    "    - input_size : number of neurons in the first layer \n",
    "    (aka latent space dimension)\n",
    "    - hidden_size : number of neurons in the hidden layer\n",
    "    - outout_size : number of neurons in the last layer\n",
    "        \"\"\"\n",
    "        super(MultilayerPerceptron, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size  = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.output = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        # self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden = self.hidden(x)\n",
    "        relu = self.relu(hidden)\n",
    "        output = self.output(relu)\n",
    "        output = self.sigmoid(output)\n",
    "        # output = self.relu(output)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilayerPerceptron(\n",
      "  (hidden): Linear(in_features=2, out_features=500, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (output): Linear(in_features=500, out_features=784, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "test = MultilayerPerceptron(2, 500, 784)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, requires_grad=True)\n",
    "y_random = test.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    \"\"\"\n",
    "    takes a tensor as input and returns an image\n",
    "    \"\"\"\n",
    "    \n",
    "    np_img = img.detach().numpy()\n",
    "    plt.imshow(np.reshape(np_img,(28,28)), cmap='gray_r' )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b786160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for i in range(10):\n",
    "#     imshow(test.forward(x[i,:]))\n",
    "imshow(test.forward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADFCAYAAAARxr1AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b786160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "# get the training datasets\n",
    "train_data = datasets.MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 64\n",
    "\n",
    "# prepare data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                           num_workers=num_workers)\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "images_np = images.numpy()\n",
    "\n",
    "\n",
    "# get one image from the batch\n",
    "img = np.squeeze(images_np[np.random.randint(len(images))])\n",
    "\n",
    "fig = plt.figure(figsize = (3,3)) \n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img, cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test = images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(test.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gabriel/anaconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([1, 28, 28])) that is different to the input size (torch.Size([784])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# test of what should be done with 1 obs and 1 train\n",
    "# on devrai remplacer la BCE par une loss maison (sinkhorn loss)\n",
    "\n",
    "test.train()\n",
    "epoch = 10000\n",
    "for epoch in range(epoch):\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    y_pred = test(x)\n",
    "    # Compute Loss\n",
    "    loss = criterion(y_pred, img_test)\n",
    "   \n",
    "    # print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.eval()\n",
    "y_pred = test(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDD9RUAw/UVAMP1FQDD9RUP8HISbM4yP37ngAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1040b99b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngaAIPxAU4QeCIvxAUP8Pt/ALPExulGgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e545898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for i in range(10):\n",
    "#     imshow(img_test[i])\n",
    "imshow(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "\n",
    "def cost_matrix(x, y):\n",
    "    \"\"\"\n",
    "    computes the cost matrix between two tensors\n",
    "    each entry is the pairwise squared distance.\n",
    "    \n",
    "    tensors have been flattened beforehand\n",
    "    \n",
    "    ultra costly to compute, must be optimized\n",
    "    \"\"\"\n",
    "    \n",
    "    x_lin = x.view(28*28, 1)\n",
    "    y_lin = y.view(28*28, 1)\n",
    "    \n",
    "    d, p = x_lin.size()[1], y_lin.size()[1]\n",
    "    \n",
    "    C = torch.cdist(x_lin , y_lin)\n",
    "    C[torch.isnan(C)] = 0\n",
    "\n",
    "        \n",
    "    return C\n",
    "\n",
    "\n",
    "def sinkhorn_wasserstein(x, y, C, epsilon=0.1, max_iters = 100):\n",
    "    \"\"\"\n",
    "    uses sinkhorn algorithm to approximate the optimal\n",
    "    transport plan between two input measures x and y.\n",
    "    \n",
    "    computes the cost matrix (l2 norm) and alternate\n",
    "    projections to compute the \n",
    "    \"\"\"\n",
    "    \n",
    "    # reshape the input tensors\n",
    "    x_lin = x.view(1,-1)\n",
    "    y_lin = y.view(1,-1)\n",
    "        \n",
    "    # Compute the kernel matrix K\n",
    "    K = torch.exp(-C/epsilon)\n",
    "    \n",
    "    # Alternate projections\n",
    "    v = torch.ones(x_lin.size()[1])\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        u = x_lin / torch.mv(K,v)\n",
    "        u = u.squeeze()\n",
    "        v = y_lin / torch.mv(K.t(),u)\n",
    "        v = v.squeeze()\n",
    "        \n",
    "    diag_u = torch.diag(u)\n",
    "    diag_v = torch.diag(v)\n",
    "    u_dot_K = torch.mm(diag_u,K)\n",
    "    \n",
    "    # Approximation of the optimal transport plan\n",
    "    P_L = torch.mm(u_dot_K,diag_v)\n",
    "    \n",
    "    # Approximation of the Wasserstein Loss\n",
    "    W_L = torch.trace(torch.mm(P_L.t(),C))\n",
    "\n",
    "    return W_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sinkhorn_loss(x,y, epsilon = 0.1, max_iters = 100):\n",
    "    \"\"\"\n",
    "    wrapper of the two functions\n",
    "    \"\"\"\n",
    "    \n",
    "    # costs\n",
    "    C_xx = cost_matrix(x,x)\n",
    "    C_xy = cost_matrix(x,y)\n",
    "    C_yy = cost_matrix(y,y)\n",
    "    \n",
    "    # Wasserstein losses\n",
    "    W_xx = sinkhorn_wasserstein(x,x, C_xx, epsilon = epsilon, max_iters = max_iters)\n",
    "    W_xy = sinkhorn_wasserstein(x,y, C_xy, epsilon = epsilon, max_iters = max_iters)\n",
    "    W_yy = sinkhorn_wasserstein(y,y, C_yy, epsilon = epsilon, max_iters = max_iters)\n",
    "    \n",
    "    # Return the sinkhorn loss\n",
    "    return 2 * W_xy - W_xx - W_yy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sinkhorn_loss(img_test, y_pred)\n",
    "b = sinkhorn_loss(img_test, y_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(57.0912, grad_fn=<SubBackward0>)\n",
      "tensor(nan, grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pairwise_distances(x, y, method='l1'):\n",
    "    n = x.size()[0]\n",
    "    m = y.size()[0]\n",
    "    d = x.size()[1]\n",
    "\n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "\n",
    "    if method == 'l1':\n",
    "        dist = torch.abs(x - y).sum(2)\n",
    "    else:\n",
    "        dist = torch.pow(x - y, 2).sum(2)\n",
    "\n",
    "    return dist.float()\n",
    "\n",
    "def dmat(x,y):\n",
    "    mmp1 = torch.stack([x] * x.size()[0])\n",
    "    mmp2 = torch.stack([y] * y.size()[0]).transpose(0, 1)\n",
    "    mm = torch.sum((mmp1 - mmp2) ** 2, 2).squeeze()\n",
    "\n",
    "    return mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairwise_distances(img_test.view(1,-1), y_pred.view(1,-1))\n",
    "a = dmat(y_pred.view(1,-1), y_pred.view(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [784, 784]], which is output 0 of CdistBackward, is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-5ce74ef09ce6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [784, 784]], which is output 0 of CdistBackward, is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "# ce qu'on doit faire en théorie (tout simplement en fait)\n",
    "# cependant pas avec une observation mais un batch assez conséquent (pour avoir une meilleure approx des\n",
    "# mesures empiriques)\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "test.train()\n",
    "\n",
    "epoch = 1\n",
    "for epoch in range(epoch):\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    y_pred = test(x)\n",
    "    # Compute Loss\n",
    "    loss = sinkhorn_loss(y_pred, img_test)\n",
    "   \n",
    "    # print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "p = 4\n",
    "q = 5\n",
    "\n",
    "A = np.zeros((p,q))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for (i,j) in it.product(range(p),range(q)):\n",
    "    A[i,j] += 1\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000\n",
    "m = 5000\n",
    "d = 1\n",
    "\n",
    "X = np.random.randn(n,d)\n",
    "Y = np.random.randn(m,d)\n",
    "\n",
    "a = np.ones(n)\n",
    "b = np.ones(m)\n",
    "\n",
    "C = ((X[:, None] - Y)**2).sum(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5098, 2.0605, 0.9203,  ..., 0.7981, 0.7966, 0.1420],\n",
       "        [1.6483, 2.1990, 1.0588,  ..., 0.6596, 0.9351, 0.2805],\n",
       "        [2.4345, 2.9851, 1.8450,  ..., 0.1266, 1.7212, 1.0667],\n",
       "        ...,\n",
       "        [1.5458, 2.0964, 0.9562,  ..., 0.7621, 0.8325, 0.1780],\n",
       "        [0.7211, 1.2718, 0.1316,  ..., 1.5867, 0.0079, 0.6466],\n",
       "        [4.6960, 5.2467, 4.1065,  ..., 2.3881, 3.9828, 3.3283]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.96759035e+00, 7.74718904e-01, 1.38203962e-04, ...,\n",
       "        5.24413757e+00, 8.66872268e-01, 1.86056441e-04],\n",
       "       [5.07514095e+00, 3.83476676e-01, 7.43556142e-02, ...,\n",
       "        6.50726653e+00, 4.49078928e-01, 6.11503607e-02],\n",
       "       [1.79565118e+00, 2.34715634e+00, 4.09735685e-01, ...,\n",
       "        2.68352294e+00, 2.50564133e+00, 4.42893263e-01],\n",
       "       ...,\n",
       "       [2.91761171e+00, 1.35480404e+00, 7.39966779e-02, ...,\n",
       "        4.02495432e+00, 1.47583398e+00, 8.84584023e-02],\n",
       "       [2.59637566e+00, 1.58945271e+00, 1.36011812e-01, ...,\n",
       "        3.64601607e+00, 1.72033015e+00, 1.55388959e-01],\n",
       "       [3.42121494e+00, 1.04532146e+00, 1.70230571e-02, ...,\n",
       "        4.61295784e+00, 1.15194759e+00, 2.42950538e-02]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((X[:, None] - Y)**2).sum(axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pairwise_distances(x, y=None):\n",
    "    '''\n",
    "    Input: x is a Nxd matrix\n",
    "           y is an optional Mxd matirx\n",
    "    Output: dist is a NxM matrix where dist[i,j] is the square norm between x[i,:] and y[j,:]\n",
    "            if y is not given then use 'y=x'.\n",
    "    i.e. dist[i,j] = ||x[i,:]-y[j,:]||^2\n",
    "    '''\n",
    "    x_norm = (x**2).sum(1).view(-1, 1)\n",
    "    if y is not None:\n",
    "        y_t = torch.transpose(y, 0, 1)\n",
    "        y_norm = (y**2).sum(1).view(1, -1)\n",
    "    else:\n",
    "        y_t = torch.transpose(x, 0, 1)\n",
    "        y_norm = x_norm.view(1, -1)\n",
    "    \n",
    "    dist = x_norm + y_norm - 2.0 * torch.mm(x, y_t)\n",
    "    # Ensure diagonal is zero if x=y\n",
    "    # if y is None:\n",
    "    #     dist = dist - torch.diag(dist.diag)\n",
    "    return torch.clamp(dist, 0.0, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_flat = img_test.view(28*28, 1)\n",
    "y_flat = y_pred.view(28*28, 1)\n",
    "X_tens = torch.from_numpy(X)\n",
    "Y_tens = torch.from_numpy(Y)\n",
    "# pairwise_distances(x_flat, y_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist = torch.pow(x_flat[:,None] - y_flat, 2).sum(2)\n",
    "dist = torch.pow(X_tens[:,None] - Y_tens, 2).sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2795e+00, 4.2456e+00, 8.4697e-01,  ..., 6.3693e-01, 6.3453e-01,\n",
       "         2.0178e-02],\n",
       "        [2.7169e+00, 4.8355e+00, 1.1211e+00,  ..., 4.3506e-01, 8.7434e-01,\n",
       "         7.8702e-02],\n",
       "        [5.9266e+00, 8.9110e+00, 3.4039e+00,  ..., 1.6019e-02, 2.9626e+00,\n",
       "         1.1378e+00],\n",
       "        ...,\n",
       "        [2.3893e+00, 4.3950e+00, 9.1440e-01,  ..., 5.8086e-01, 6.9307e-01,\n",
       "         3.1678e-02],\n",
       "        [5.2005e-01, 1.6175e+00, 1.7329e-02,  ..., 2.5178e+00, 6.2434e-05,\n",
       "         4.1812e-01],\n",
       "        [2.2053e+01, 2.7528e+01, 1.6864e+01,  ..., 5.7032e+00, 1.5863e+01,\n",
       "         1.1077e+01]], dtype=torch.float64)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
